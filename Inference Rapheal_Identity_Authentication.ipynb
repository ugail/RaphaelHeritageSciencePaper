{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOHklV7VXGpOBl/DLkesKU2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import glob\n","import joblib\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing import image as keras_image\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.models import load_model\n","import math\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","def scale_inverse_log(x, x_min, x_max, y_min, y_max):\n","    # Check input boundaries\n","    if x < x_min or x > x_max:\n","        return \"Input x must be within the range [x_min, x_max]\"\n","\n","    # Calculate inverse log of x\n","    inv_log_x = -1 / math.log(x + 1)\n","\n","    # Calculate inverse log of x_min and x_max\n","    inv_log_x_min = -1 / math.log(x_min + 1)\n","    inv_log_x_max = -1 / math.log(x_max + 1)\n","\n","    # Scale the inverse logarithmic value to the target range [y_min, y_max]\n","    y = y_min + (inv_log_x - inv_log_x_min) * (y_max - y_min) / (inv_log_x_max - inv_log_x_min)\n","\n","    return y\n","\n","\n","# Function to load and preprocess image\n","def load_and_preprocess_image(img_path):\n","    img = keras_image.load_img(img_path, target_size=(224, 224))\n","    img = keras_image.img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    return preprocess_input(img)\n","\n","def extract_features(img_path, model):\n","    img = load_and_preprocess_image(img_path)\n","    features = model.predict(img)\n","    return features.reshape(-1)\n","\n","def visualize_probabilities(categories, probabilities):\n","    # Load image\n","    img = Image.open(test_image_path)\n","\n","    # Create subplots\n","    fig, ax1 = plt.subplots(figsize=(10, 5))\n","\n","    # Plot image on first subplot\n","    ax1.imshow(img)\n","    ax1.axis('off')\n","    plt.show()\n","\n","    # Create a bar plot\n","    plt.figure(figsize=(10, 5))\n","    plt.bar(categories, probabilities)\n","    plt.xlabel('Classes')\n","    plt.ylabel('Probability')\n","    plt.title('Probabilities for each class')\n","    plt.show()\n","\n","# Function to calculate edge features using Canny edge detector\n","def calculate_canny_edges(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    edges = cv2.Canny(gray, 100, 200)\n","    return np.std(edges)\n","\n","# Function to calculate edge features using Sobel operator\n","def calculate_sobel_edges(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n","    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n","    return np.std(sobelx), np.std(sobely)\n","\n","# Function to calculate edge features using Laplacian operator\n","def calculate_laplacian_edges(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n","    return np.std(laplacian)\n","\n","# Function to calculate edge features using Scharr operator\n","def calculate_scharr_edges(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    scharrx = cv2.Scharr(gray, cv2.CV_64F, 1, 0)\n","    scharry = cv2.Scharr(gray, cv2.CV_64F, 0, 1)\n","    return np.std(scharrx), np.std(scharry)\n","\n","# Function to calculate all edge features\n","def calculate_features(img):\n","    canny_edges = calculate_canny_edges(img)\n","    sobel_edges_x, sobel_edges_y = calculate_sobel_edges(img)\n","    laplacian_edges = calculate_laplacian_edges(img)\n","    scharr_edges_x, scharr_edges_y = calculate_scharr_edges(img)\n","    return np.array([canny_edges, sobel_edges_x, sobel_edges_y, laplacian_edges, scharr_edges_x, scharr_edges_y])\n","\n","def compare_image_with_dataset(test_image_path, image_dir, categories):\n","\n","\n","    # Load test image\n","    test_image = cv2.imread(test_image_path)\n","\n","\n","    # Load the final model\n","    svm_final = joblib.load(Model_Path)\n","\n","    # Load the saved model\n","    model = load_model(ResNet_Path)\n","\n","    # Extract features from the test image\n","    test_image_features = extract_features(test_image_path, model)\n","\n","    # Use the loaded model to predict the category of the test image\n","    predicted_category = svm_final.predict([test_image_features])[0]\n","\n","    # Calculate probabilities for each category\n","    probabilities = svm_final.predict_proba([test_image_features])[0]\n","\n","    categories = ['Raphael', 'Not Raphael']\n","\n","    # Calculate features of test image\n","    test_features = calculate_features(test_image)\n","\n","    # Normalize test features to get weights\n","    weights = test_features / np.sum(test_features)\n","\n","    # Load all images in directory\n","    formats = ('*.jpg', '*.png', '*.bmp')  # Add or remove formats as needed\n","    image_paths = []\n","    for fmt in formats:\n","        image_paths.extend(glob.glob(f\"{image_dir}/{fmt}\"))\n","\n","    # Calculate the total feature values and the count of images\n","    total_features = np.zeros_like(test_features)\n","    image_count = 0\n","\n","    for image_path in image_paths:\n","        # Load image\n","        image = cv2.imread(image_path)\n","\n","        # Calculate features of image\n","        image_features = calculate_features(image)\n","\n","        # Add to total and increment count (multiply by weights here)\n","        total_features += image_features * weights\n","        image_count += 1\n","\n","    # Calculate the weighted average feature values\n","    average_features = total_features / image_count if image_count else np.zeros_like(test_features)\n","\n","    # Compare average features with test image\n","    difference = np.abs(test_features - average_features)\n","\n","    # Sum of differences\n","    sum_diff = np.sum(difference)\n","\n","    max_diff = np.max(difference)\n","    min_diff = np.min(difference)\n","    mean_diff = np.mean(difference)\n","    edge_threshold = (mean_diff - min_diff) / mean_diff\n","\n","\n","\n","#penalise for edge information (these values can be found by experimentation)\n","    if mean_diff < 50:\n","        mean_diff = 400\n","        probabilities[0] = probabilities[0] - 0.3\n","\n","    if mean_diff > 400:\n","        mean_diff = 400\n","        probabilities[0] = probabilities[0] - 0.3\n","\n","    if mean_diff < 150:\n","        mean_diff = 150\n","\n","    scale_ = scale_inverse_log(mean_diff, x_min=150, x_max=400, y_min=0.0, y_max=-0.99)\n","    print (scale_)\n","\n","    threshold = 0.95* probabilities[0] + 0.05*scale_\n","    if threshold < 0:\n","       threshold = 0.05\n","\n","    probabilities[0] = threshold\n","    probabilities[1] = 1 - threshold\n","    print(\"Probabilities\", probabilities[0], probabilities[1])\n","    visualize_probabilities(categories, probabilities)\n","\n","\n","\n","\n","#Load the trained model and Resnet base model\n","ResNet_Path = \"/content/drive/MyDrive/Colab Notebooks/models/resnet50_model.h5\"\n","Model_Path = \"/content/drive/MyDrive/Colab Notebooks/models/resnet50_model.h5/28_09_2023_svm_final_model.pkl\"\n","\n","\n","# Define categories\n","categories = ['Raphael', 'Not Raphael']\n","\n","# Define directory containing test images and training images (for edge feature extraction)\n","test_image_dir = \"/content/drive/MyDrive/Colab Notebooks/Tests\"\n","image_dir = \"/content/drive/MyDrive/Colab Notebooks/data/Raphael\"\n","\n","# Get all test images in directory\n","formats = ('*.jpg', '*.png', '*.bmp')\n","test_image_paths = []\n","for fmt in formats:\n","    test_image_paths.extend(glob.glob(f\"{test_image_dir}/{fmt}\"))\n","\n","# Loop through each test image and compare with dataset\n","for test_image_path in test_image_paths:\n","    compare_image_with_dataset(test_image_path, image_dir, categories)\n"],"metadata":{"id":"4dMkQMwvsVhn"},"execution_count":null,"outputs":[]}]}